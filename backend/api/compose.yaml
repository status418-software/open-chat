services:
  api:
    build:
      context: ./
    container_name: api
    ports:
      - "8080:8080"
    environment:
      # - OLLAMA_MODEL=tinyllama
      - OLLAMA_MODEL=llama3.2:1b
    networks:
      - ollama-net

networks:
  ollama-net:
    external: true
